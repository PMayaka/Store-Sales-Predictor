{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97de345",
   "metadata": {},
   "source": [
    "# Walmart sales forecasting using RNN (LSTM )\n",
    "1. data preprocessing.\n",
    " \n",
    " Some things to consider when cleaning. we have to map null values to0. We also have to make sure to parse date time correctly. \n",
    "\n",
    "2. visualize the data to get a general idea\n",
    "\n",
    "\n",
    "# References:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf26f63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c459c2a",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df307f89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv)\n",
    "test = pd.read_csv('test.csv')\n",
    "features = pd.read_csv('features.csv')\n",
    "store = pd.read_csv(os.path.join('data', filepath))\n",
    "\n",
    "train = train.merge(features, on=[\"Store\", \"Date\", \"IsHoliday\"], how=\"left\")\n",
    "train = train.merge(stores, on=\"Store\", how=\"left\")\n",
    "\n",
    "test = test.merge(features, on=[\"Store\", \"Date\", \"IsHoliday\"], how=\"left\")\n",
    "test = test.merge(stores, on=\"Store\", how=\"left\")\n",
    "\n",
    "for df in [train, test]:\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Week'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "    df['Day'] = df['Date'].dt.dayofweek\n",
    "\n",
    "train['Type'] = train['Type'].map({'A': 0, 'B': 1, 'C': 2})\n",
    "test['Type'] = test['Type'].map({'A': 0, 'B': 1, 'C': 2})\n",
    "\n",
    "\n",
    "features_cols = ['Store', 'Dept', 'IsHoliday', 'Temperature', 'Fuel_Price',\n",
    "                 'CPI', 'Unemployment', 'Size', 'Type',\n",
    "                 'Year', 'Month', 'Week', 'Day']\n",
    "\n",
    "X_train = train[features_cols]\n",
    "y_train = train['Weekly_Sales']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f29824",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "seq_len = 7 # for 7 days a week\n",
    "input_size = 13 # since we have 13 numerical features after data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa47f1b4",
   "metadata": {},
   "source": [
    "# LSTM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd162c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ForecastLSTM(nn.Module):\n",
    "   \n",
    "    def __init__(self, input_dim, hidden_dim, num_layers,output_dim, bias=True):\n",
    "        super(ForecastLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,bias)\n",
    "        self.fc = nn.Linear(hidden_dim,output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        ht = torch.zeros(self.hidden_dim,device=device)\n",
    "        ct = torch.zeros(self.hidden_dim,device=device)\n",
    "\n",
    "        output, _ = self.lstm_cell(x[i], ht, ct)\n",
    "\n",
    "        output = self.fc(output[:,-1,:])\n",
    "        return output\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
